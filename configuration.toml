[architecture]
# Major architectural options
transformer_type       = "Encoder_Decoder"  # TransformerType enum
num_encoder_layers     = 6
num_decoder_layers     = 6
d_model                = 512
# These ones are only relevant if using a custom transformer architecture
output_probs           = true
use_masked_att_encoder = false
use_masked_att_decoder = true

# Layer options
use_resid_connection   = true
pre_norm               = true

# Attention options
num_attention_heads    = 8

# Feed-forward options
d_ff                   = 2048
    
# Positional encoding options
pos_enc_type           = "Sinusoidal"  # PositionalEncodingType enum
context_window_length  = 512

# Normalization options
norm_type              = "Scale_Norm"  # NormType enum
layer_norm_epsilon     = 1e-5
    
# Embedding options
fix_norm               = true


[training]
# Length of training
max_epochs             = 200
epoch_size             = 1000

# Batching
batch_size             = 4096
sort_by_tgt_only       = true

# Learning rate
lr.lr_strategy         = "NoWarmup_ValDecay"
# Used by Warmup_*
lr.lr_scale            = 1.0
lr.warmup_steps        = 4000
# Used by *_ValDecay
lr.lr_decay            = 0.8
lr.patience            = 3
lr.stop_lr             = 5e-5
# Used by NoWarmup_ValDecay
lr.start_lr            = 3e-4

# Evaluation metric for early stopping
eval_metric            = "BLEU"

# Gradient clipping
clip_grad              = "Norm"
clip_grad_max          = 0.5
clip_grad_scale        = 1.0

# Initialization
use_toan_init          = true

# Dropout options
dropout                = 0.3
att_dropout            = 0.3
ff_dropout             = 0.3
word_dropout           = 0.1

# Label smoothing
label_smoothing        = 0.1
label_smooth_eos       = true
label_smooth_unk       = true


[generation]
# How many sentences can the GPU handle at a time
max_parallel_sentences = 100

# Number of generations
num_beams_or_samples   = 5

# Length of generations
use_rel_max_len        = true
rel_max_len            = 50
abs_max_len            = 300

# Decoding method
decoding_method        = "Beam_Search"
# Sampling params
sampling_k             = 0
sampling_p             = 1.0
sampling_temp          = 1.0
# Beam search params
allow_empty_string     = true
length_normalization   = "None"
length_reward_gamma    = 0.0
length_norm_alpha      = 0.0

# MBR params
# If using MBR, you must manually set the decoding
# method for the candidates and hypotheses.
# If the candidates and hypotheses are the same set,
# use [generation.share]. If they are different, use
# [generation.cand] and [generation.hypo].
# You may also manually set the other generation
# parameters by making new copies of those parameters
# under generation.share, generation.cand or generation.hypo.
# (Please only use whichever of generation.cand, generation.hypo,
# and generation.share you actually need; otherwise it will break.)
mbr_share_sents        = true
weight_hypos_equally   = true
[generation.cand]
decoding_method        = "Sampling"
[generation.hypo]
decoding_method        = "Sampling"
[generation.share]
decoding_method        = "Sampling"
# You can do nested MBR if you like, to arbitrary depth.
# If you are doing this, you can construct the config
# options in a nested way, by making headings like
# [generation.hypo.share.cand].
# For each instance of MBR, the only required parameters
# are [prefix].mbr_share_sents, and either
# [prefix].cand.decoding_method and [prefix].hypo.decoding_method
# or just [prefix].share.decoding_method based on whether
# [prefix].mbr_share_sents is false or true.
# You will also want to set the number of sentences to keep
# from a nested MBR batch, using num_beams_or_samples.
# You may also redefine any other parameters.
# If a parameter is not specified it will default to
# the previous level of nesting.
